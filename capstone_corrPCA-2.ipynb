{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ab2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"xelatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7df4e94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "churn = pd.read_csv('Churn_Modelling.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e8370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sn.heatmap(churn.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f618cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_clean = churn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9a1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = {'Geography', 'Gender'}\n",
    "predict_cols = set((churn.columns)) - {'CustomerId', 'Exited', 'Surname'}\n",
    "num_cols = predict_cols- categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8eefc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sclr = StandardScaler()\n",
    "lblr = LabelEncoder()\n",
    "sclr.fit(churn[num_cols])\n",
    "for col in categorical_cols:\n",
    "    churn_clean[col] = lblr.fit_transform(churn[col])\n",
    "churn_clean[list(num_cols)] = sclr.transform(churn[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8268f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.figure()\n",
    "plt.title('Correlation Matrix')\n",
    "# sn.set(font_scale=.3)\n",
    "# sn.set(rc = {'figure.figsize':(2,2)})\n",
    "plt.subplots_adjust(left=0.2, bottom=0.3)\n",
    "sn.heatmap(churn_clean[predict_cols].corr())\n",
    "plt.savefig('corr.pgf', format='pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432c73b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>-0.440036</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CustomerId   Surname  CreditScore  Geography  Gender       Age  \\\n",
       "RowNumber                                                                   \n",
       "1            15634602  Hargrave    -0.326221          0       0  0.293517   \n",
       "2            15647311      Hill    -0.440036          2       0  0.198164   \n",
       "\n",
       "             Tenure   Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "RowNumber                                                                 \n",
       "1         -1.041760 -1.225848      -0.911583   0.646092        0.970243   \n",
       "2         -1.387538  0.117350      -0.911583  -1.547768        0.970243   \n",
       "\n",
       "           EstimatedSalary  Exited  \n",
       "RowNumber                           \n",
       "1                 0.021886       1  \n",
       "2                 0.216534       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e80593",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(churn_clean[predict_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6dbfb9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (659848046.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/9x/vplh0l8j4fn7lnfwvn9txw4m0000gn/T/ipykernel_50064/659848046.py\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    sn.set(font=)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "sn.set(font=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac0c515",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.figure()\n",
    "plt.xticks(np.arange(pca.n_components_) + 1)\n",
    "plt.title('Explained Variance')\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "# plt.subplots_adjust(left=0.3, right=0.9, bottom=0.3, top=0.9)\n",
    "plt.savefig('explained_variance.pgf',format='pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66fa0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.figure()\n",
    "plt.xticks(list(range(len(pca.components_))))\n",
    "PC_values = np.arange(pca.n_components_) + 1\n",
    "plt.plot(PC_values, pca.explained_variance_ratio_, linewidth=.5, color='blue')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal component')\n",
    "plt.ylabel('Explained variance')\n",
    "# plt.subplots_adjust(left=0.3, right=0.9, bottom=0.3, top=0.9)\n",
    "plt.savefig('scree.pgf',format='pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc4ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### FEATURE SELECTION ###\n",
    "#########################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "\n",
    "### Initialize Boruta\n",
    "forest = RandomForestClassifier(\n",
    "   n_jobs = -1, \n",
    "   max_depth = 7, \n",
    "   verbose = 0\n",
    ")\n",
    "boruta = BorutaPy(\n",
    "   estimator = forest, \n",
    "   n_estimators = 'auto',\n",
    "   max_iter = 500, # number of trials to perform, \n",
    "   verbose = 0\n",
    ")\n",
    "### modify datatype for Boruta (it accepts np.array, not pd.DataFrame)\n",
    "\n",
    "## NOTE: Omitted Surname and Customer ID\n",
    "churn_data_x = churn_clean[list(predict_cols)]\n",
    "churn_data_y = churn_clean[['Exited']]\n",
    "\n",
    "churn_data_x_numpy = churn_data_x.to_numpy()\n",
    "churn_data_y_numpy = churn_data_y.to_numpy()\n",
    "\n",
    "## Boruta has already been run so for future runs of this notebook we avoid a re-run\n",
    "## To re-run Boruta, switch runBortua to True\n",
    "runBoruta = False\n",
    "\n",
    "if runBoruta:\n",
    "    boruta.fit(churn_data_x_numpy, churn_data_y_numpy)\n",
    "\n",
    "    ## Green Area variables have been cleared as significant, blue area variables are still uncertain\n",
    "    green_area = churn_data_x.columns[boruta.support_].to_list()\n",
    "    blue_area = churn_data_x.columns[boruta.support_weak_].to_list()\n",
    "    print('features in the green area:', green_area)\n",
    "    print('features in the blue area:', blue_area)\n",
    "else:\n",
    "   green_area = ['Age', 'EstimatedSalary', 'CreditScore', 'Geography', 'NumOfProducts', 'IsActiveMember', 'Balance']\n",
    "   blue_area = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### MODEL IMPLEMENTATION, RANDOM FOREST ###\n",
    "###########################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(churn_data_x[green_area], churn_data_y, test_size = 0.2, random_state = 20)\n",
    "\n",
    "## Random Grid search has already been run, to re-run, turn runRandomGrid to True\n",
    "runRandomGrid = False \n",
    "\n",
    "if runRandomGrid:\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 500, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 25, num = 10)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4, 10]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    rf = RandomForestClassifier(class_weight='balanced')\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=10, random_state=42, n_jobs = -1)\n",
    "\n",
    "    rf_random.fit(x_train, y_train)\n",
    "    rf_random.score(x_test, y_test)\n",
    "\n",
    "    ### Best Params ###\n",
    "    '''\n",
    "    {'n_estimators': 1000,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': 16,\n",
    "    'bootstrap': False}\n",
    "    '''\n",
    "\n",
    "classifier = RandomForestClassifier(min_samples_leaf = 1, max_features = 'sqrt', max_depth=16, bootstrap = False, n_estimators = 1000, random_state= 1, class_weight='balanced')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "print('------------------------------------------------')\n",
    "print('Accuracy :', classifier.score(x_test,y_test))\n",
    "\n",
    "y_preds = classifier.predict(x_test)\n",
    "f1_score = metrics.f1_score(y_test, y_preds)\n",
    "print('F1 :', f1_score)\n",
    "print('------------------------------------------------')\n",
    "\n",
    "\n",
    "for i,v in enumerate(classifier.feature_importances_):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### MODEL IMPLEMENTATION, RANDOM FOREST ###\n",
    "###########################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(churn_data_x[green_area], churn_data_y, test_size = 0.2, random_state = 20)\n",
    "\n",
    "## Random Grid search has already been run, to re-run, turn runRandomGrid to True\n",
    "runRandomGrid = False \n",
    "\n",
    "if runRandomGrid:\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 500, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 25, num = 10)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4, 10]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    rf = RandomForestClassifier(class_weight='balanced')\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=10, random_state=42, n_jobs = -1)\n",
    "\n",
    "    rf_random.fit(x_train, y_train)\n",
    "    rf_random.score(x_test, y_test)\n",
    "\n",
    "    ### Best Params ###\n",
    "    '''\n",
    "    {'n_estimators': 1000,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': 16,\n",
    "    'bootstrap': False}\n",
    "    '''\n",
    "\n",
    "classifier = RandomForestClassifier(min_samples_leaf = 1, max_features = 'sqrt', max_depth=16, bootstrap = False, n_estimators = 1000, random_state= 1, class_weight='balanced')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "print('------------------------------------------------')\n",
    "print('Accuracy :', classifier.score(x_test,y_test))\n",
    "\n",
    "y_preds = classifier.predict(x_test)\n",
    "f1_score = metrics.f1_score(y_test, y_preds)\n",
    "print('F1 :', f1_score)\n",
    "print('------------------------------------------------')\n",
    "\n",
    "\n",
    "for i,v in enumerate(classifier.feature_importances_):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### MODEL IMPLEMENTATION, RANDOM FOREST ###\n",
    "###########################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(churn_data_x[green_area], churn_data_y, test_size = 0.2, random_state = 20)\n",
    "\n",
    "## Random Grid search has already been run, to re-run, turn runRandomGrid to True\n",
    "runRandomGrid = False \n",
    "\n",
    "if runRandomGrid:\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 500, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 25, num = 10)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4, 10]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    rf = RandomForestClassifier(class_weight='balanced')\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=10, random_state=42, n_jobs = -1)\n",
    "\n",
    "    rf_random.fit(x_train, y_train)\n",
    "    rf_random.score(x_test, y_test)\n",
    "\n",
    "    ### Best Params ###\n",
    "    '''\n",
    "    {'n_estimators': 1000,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'max_depth': 16,\n",
    "    'bootstrap': False}\n",
    "    '''\n",
    "\n",
    "classifier = RandomForestClassifier(min_samples_leaf = 1, max_features = 'sqrt', max_depth=16, bootstrap = False, n_estimators = 1000, random_state= 1, class_weight='balanced')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "print('------------------------------------------------')\n",
    "print('Accuracy :', classifier.score(x_test,y_test))\n",
    "\n",
    "y_preds = classifier.predict(x_test)\n",
    "f1_score = metrics.f1_score(y_test, y_preds)\n",
    "print('F1 :', f1_score)\n",
    "print('------------------------------------------------')\n",
    "\n",
    "\n",
    "for i,v in enumerate(classifier.feature_importances_):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc93fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportanceDict = {'Features':green_area,'Importance':list(classifier.feature_importances_)}\n",
    "featureImportanceDictDF = pd.DataFrame(featureImportanceDict, columns=['Features','Importance'])\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "sns.set(rc = {'figure.figsize':(8,4)})\n",
    "plt.figure()\n",
    "sns.barplot(y='Features', x='Importance', data=featureImportanceDictDF).set_title('Feature Importance')\n",
    "plt.subplots_adjust(left=0.2)\n",
    "plt.savefig('feature_importances.pgf',format='pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d8b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
